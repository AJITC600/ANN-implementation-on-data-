{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a47c07-3672-42d6-acd2-5990c53923ba",
   "metadata": {},
   "source": [
    "ðŸ§© Project on Anime Dataset\n",
    "\n",
    "Anime scores are usually given based on simple averages.\n",
    "I wanted to predict them using the actual synopsis text and show statistics like popularity, members, and episodes.\n",
    "\n",
    "ðŸ“Š Dataset Used--> anime_dataset.csv\n",
    "\n",
    "Columns included--> title,  synopsis,  genres,  episodes,  popularity,  members,   studios,  score\n",
    "âœ” Dropped column: year\n",
    "âœ” Target variable: score\n",
    "âœ” Object column processed as text sequence\n",
    "\n",
    "ðŸ§° Tools we are using-->\n",
    "Python, Pandas, NumPy, TensorFlow/Keras, Scikit-learn, Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e63518-4424-4ac3-b519-c89491741939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b17784-0e3c-409f-94fe-794dec2563e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "      <th>episodes</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>studios</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>8.57</td>\n",
       "      <td>['Action', 'Award Winning', 'Drama', 'Suspense...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Centuries ago, mankind was slaughtered to near...</td>\n",
       "      <td>1</td>\n",
       "      <td>4245518</td>\n",
       "      <td>['Wit Studio']</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Death Note</td>\n",
       "      <td>8.62</td>\n",
       "      <td>['Supernatural', 'Suspense', 'Psychological', ...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Brutal murders, petty thefts, and senseless vi...</td>\n",
       "      <td>2</td>\n",
       "      <td>4186098</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.10</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy', 'M...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>3</td>\n",
       "      <td>3588803</td>\n",
       "      <td>['Bones']</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One-Punch Man</td>\n",
       "      <td>8.48</td>\n",
       "      <td>['Action', 'Comedy', 'Adult Cast', 'Parody', '...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>The seemingly unimpressive Saitama has a rathe...</td>\n",
       "      <td>4</td>\n",
       "      <td>3443899</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba</td>\n",
       "      <td>8.42</td>\n",
       "      <td>['Action', 'Award Winning', 'Supernatural', 'H...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Ever since the death of his father, the burden...</td>\n",
       "      <td>5</td>\n",
       "      <td>3340293</td>\n",
       "      <td>['ufotable']</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  score  \\\n",
       "0                   Attack on Titan   8.57   \n",
       "1                        Death Note   8.62   \n",
       "2  Fullmetal Alchemist: Brotherhood   9.10   \n",
       "3                     One-Punch Man   8.48   \n",
       "4    Demon Slayer: Kimetsu no Yaiba   8.42   \n",
       "\n",
       "                                              genres  episodes  \\\n",
       "0  ['Action', 'Award Winning', 'Drama', 'Suspense...      25.0   \n",
       "1  ['Supernatural', 'Suspense', 'Psychological', ...      37.0   \n",
       "2  ['Action', 'Adventure', 'Drama', 'Fantasy', 'M...      64.0   \n",
       "3  ['Action', 'Comedy', 'Adult Cast', 'Parody', '...      12.0   \n",
       "4  ['Action', 'Award Winning', 'Supernatural', 'H...      26.0   \n",
       "\n",
       "                                            synopsis  popularity  members  \\\n",
       "0  Centuries ago, mankind was slaughtered to near...           1  4245518   \n",
       "1  Brutal murders, petty thefts, and senseless vi...           2  4186098   \n",
       "2  After a horrific alchemy experiment goes wrong...           3  3588803   \n",
       "3  The seemingly unimpressive Saitama has a rathe...           4  3443899   \n",
       "4  Ever since the death of his father, the burden...           5  3340293   \n",
       "\n",
       "          studios    year  \n",
       "0  ['Wit Studio']  2013.0  \n",
       "1    ['Madhouse']  2006.0  \n",
       "2       ['Bones']  2009.0  \n",
       "3    ['Madhouse']  2015.0  \n",
       "4    ['ufotable']  2019.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Csv File\n",
    "df = pd.read_csv('C:/Users/USER/Desktop/Kaggle/Anime Dataset/anime_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1a83a8-9ca3-4a0e-ae25-55f4b2260c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "score           0\n",
       "genres          0\n",
       "episodes        0\n",
       "synopsis        0\n",
       "popularity      0\n",
       "members         0\n",
       "studios         0\n",
       "year          168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling missing values\n",
    "df['episodes'] = df['episodes'].fillna(df['episodes'].mean())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139d33f0-bdb1-438c-b8d7-65d5c5ebdef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          object\n",
       "score         float64\n",
       "genres         object\n",
       "episodes      float64\n",
       "synopsis       object\n",
       "popularity      int64\n",
       "members         int64\n",
       "studios        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleting the column with most null values\n",
    "df=df.drop('year',axis=1)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3be8b-598e-4a20-b601-d804c8473488",
   "metadata": {},
   "source": [
    "ðŸ”¥ Techniques Used in this dataset  -->  Tokenization of synopsis text, Sequence padding (max length = 200), Scaling numeric features,                 Multi-input deep learning model,  ANN for numeric data,  SimpleRNN for text data,  Merging features for final prediction\n",
    "\n",
    "ðŸ¤– Model Architecture Used -->  Embedding Layer,  SimpleRNN Layer for text,  Dense Layers for numeric features, Concatenation of text + numeric,          Final Dense Layer predicting score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4619958e-4941-4246-b19b-7aa0e4563351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#TEXT PROCESSING\n",
    "text_col = df['synopsis'].astype('str')\n",
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(text_col)\n",
    "seq = tokenizer.texts_to_sequences(text_col)\n",
    "maxlen=200\n",
    "seq = pad_sequences(seq,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4579eb8f-f722-4b85-8d63-d08d1f2af1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#NUMERIC PROCESSING\n",
    "numeric_cols = ['episodes','popularity','members']\n",
    "X_num = df[numeric_cols].fillna(0)\n",
    "scaler = MinMaxScaler()\n",
    "X_num = scaler.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbb2bc2-72ba-4cbc-9d5b-dc8cfe47bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['score']\n",
    "#Spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xseq_train,Xseq_test,Xnum_train,Xnum_test,y_train,y_test=train_test_split(seq,X_num,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3d9c94-0dfd-4cbf-8860-33f4066bf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Embedding,SimpleRNN,Dense,Concatenate\n",
    "#Building Model\n",
    "#RNN \n",
    "input_text = Input(shape=(maxlen,))\n",
    "embed = Embedding(15000,64)(input_text)\n",
    "rnn = SimpleRNN(32)(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24843aa2-b5f5-49a4-a018-5fce1e85e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN\n",
    "input_num = Input(shape=(X_num.shape[1],))\n",
    "dense_num = Dense(32,activation='relu')(input_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2973d3b6-cb6e-4129-a7de-81714f76d0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 200, 64)      960000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 32)           3104        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           128         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64)           0           ['simple_rnn[0][0]',             \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 969,505\n",
      "Trainable params: 969,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "merged = Concatenate()([rnn,dense_num])\n",
    "dense = Dense(64,activation='relu')(merged)\n",
    "dense = Dense(32,activation='relu')(dense)\n",
    "output = Dense(1)(dense)\n",
    "model = Model([input_text,input_num],output)\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90863dea-515b-4d58-a798-49115b052df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 6s 82ms/step - loss: 38.2949 - mae: 6.0174 - val_loss: 12.7660 - val_mae: 3.3147\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 4.0511 - mae: 1.5924 - val_loss: 10.2523 - val_mae: 2.7641\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 2.1372 - mae: 1.1063 - val_loss: 1.8458 - val_mae: 0.8848\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 2s 66ms/step - loss: 0.8132 - mae: 0.6882 - val_loss: 1.6203 - val_mae: 0.8085\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 2s 74ms/step - loss: 0.4846 - mae: 0.5267 - val_loss: 1.4075 - val_mae: 0.7212\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 2s 66ms/step - loss: 0.3365 - mae: 0.4379 - val_loss: 1.3328 - val_mae: 0.6830\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.2562 - mae: 0.3831 - val_loss: 1.3174 - val_mae: 0.6818\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 2s 89ms/step - loss: 0.1890 - mae: 0.3320 - val_loss: 1.2891 - val_mae: 0.6824\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 0.1449 - mae: 0.2835 - val_loss: 1.2840 - val_mae: 0.6895\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 2s 70ms/step - loss: 0.0960 - mae: 0.2239 - val_loss: 1.2359 - val_mae: 0.6864\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "history = model.fit([Xseq_train,Xnum_train],y_train,validation_data=([Xseq_test,Xnum_test],y_test),epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087b98c8-0d03-454c-b5d9-9c6200677e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model Prediction\n",
    "y_pred = model.predict([Xseq_test,Xnum_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6804968-af76-440c-8c5e-a7bfd92acbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : 0.69\n"
     ]
    }
   ],
   "source": [
    "#Checking Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "print(f\"Error : {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3c830-b23f-4d69-876a-bc5265637446",
   "metadata": {},
   "source": [
    "ðŸ“ˆ Results--> MAE: (0.69),  MSE: (1.24)\n",
    "\n",
    "1.)Model captures strong relationships between synopsis content and popularity metrics.\n",
    "2.)Predictions were close to actual score values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28552b-3a9b-49de-95db-71abc539f039",
   "metadata": {},
   "source": [
    "âœ… Conclusion:\n",
    "\n",
    "This project demonstrates how combining text-based features with numeric attributes can significantly \n",
    "improve prediction accuracy using a hybrid ANN + SimpleRNN model.\n",
    "By processing the synopsis through a SimpleRNN and merging it with normalized numeric features, \n",
    "the model successfully learned meaningful patterns and produced reliable score predictions.\n",
    "Overall, this project strengthened my understanding of handling mixed data types, text preprocessing, \n",
    "and designing multi-input neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253101-99e3-42a9-92f6-93f64e3253d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
